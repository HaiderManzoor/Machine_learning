{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 IRS - With Synonyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information retrieval is the process of obtaining information system resources that are relevant to an information need from a collection of those resources. The core purpose of this assignment is to give you the flavor of IRS. You need to follow some steps listed below and in the end, you'll be able to build your own small IRS. So, let's start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required imports\n",
    "import numpy as np\n",
    "import fnmatch\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have 3 files containing data :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"This is my book\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/f1.png?raw=true)\n",
    "![\"This is my pen\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/f2.png?raw=true)\n",
    "![\"This is book is intersting\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/f3.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 Create Files with Dummy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to create few files with dummy data of your own choice as shown above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 Traverse Directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now, You have to traverse the directories and store all the files into a dict type variable(files_dict). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we have initialized some variables, you can add more if required.\n",
    "\n",
    "file_count = 0             # file_count to count number of files\n",
    "files_dict = {}            # files_dic to store count of every file    \n",
    "unique_word_set = set()    # unique_word_set to store all the unique words in a set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code starts here \n",
    "path = r\"C:\\Users\\hp\\Downloads\\Assignmnet 2 - IRS\\files\" #path of folder where files are placed\n",
    "files = [f for f in os.listdir(path)]# using os method listdir to get count\n",
    "file_count = len(files)\n",
    "\n",
    "def dict_files(path): #function to to store count of every file   \n",
    "    files = {}\n",
    "    i = 0\n",
    "    for filename in os.listdir(path): # iterate over each file of the directory of specific path\n",
    "        file_path = os.path.join(path,filename) #create file path\n",
    "        if os.path.isfile(file_path) and fnmatch.fnmatch(filename, '*.txt'): #check wheather its a file or not with an extension of txt only\n",
    "            files[filename] = i #assign dictionary a key with specific value\n",
    "            i +=1\n",
    "    return files # return files dictionary\n",
    "files_dict= dict_files(path)\n",
    "\n",
    "#Your code ends here       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the count of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Number  of files\n",
      " 6\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTotal Number  of files\\n\", file_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying Dictionary containing all files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dictionary containing  files\n",
      " {'f1.txt': 0, 'f2.txt': 1, 'f3.txt': 2, 'f4.txt': 3, 'f5.txt': 4}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDictionary containing  files\\n\", files_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 Extract Unique Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write code to print all the unique words in every file and store them in a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'and', 'book', 'interesting', 'is', 'my', 'pen', 'shoes', 'this', 'umbrella'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code starts here    \n",
    "def get_vocab(path):\n",
    "    words = [] #initialize a list to store words\n",
    "    for filename in os.listdir(path):\n",
    "        file_path = os.path.join(path,filename)\n",
    "        if os.path.isfile(file_path) and fnmatch.fnmatch(filename, '*.txt'):\n",
    "            f = open(file_path) # open specific file \n",
    "            get_words = f.read().lower().split() # create an array of words splitted on the basis of space\n",
    "            words.extend(get_words) #extend the empty word list with the get_word list\n",
    "    return words\n",
    "path = r\"C:\\Users\\hp\\Downloads\\Assignmnet 2 - IRS\\files\"\n",
    "words_list = get_vocab(path)\n",
    "# print(words_list) \n",
    "uniq_word_set = set(words_list) #passing the words_list into set so that we get unique vocab \n",
    "uniq_word_set\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o1.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 Create Term Document Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Term-Doc-matrix using Bag of word approach.and display its contents initially and finally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create Term doc matrix such that colmns will be unique words and all the files will be rows\n",
    "2. Write code to count all the unique words appearances in all the files and store it in a dictionary for words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "dictionary of unique words \n",
      " {'and': 0, 'umbrella': 1, 'book': 2, 'shoes': 3, 'this': 4, 'interesting': 5, 'my': 6, 'pen': 7, 'is': 8}\n",
      "\n",
      " dictionary of all words : \n",
      " {'this': 4, 'is': 5, 'my': 5, 'book': 2, 'pen': 1, 'interesting': 1, 'umbrella': 2, 'and': 1, 'shoes': 1}\n",
      "\n",
      " dictionary of files \n",
      " {'f1.txt': 0, 'f2.txt': 1, 'f3.txt': 2, 'f4.txt': 3, 'f5.txt': 4}\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here\n",
    "len_s = len(uniq_word_set)\n",
    "len_s\n",
    "term_mtrx = np.zeros((file_count,len_s)) #create a term matrix using numpy with parameters cols and rows, rows are count of files and cols are number of unique words\n",
    "print(term_mtrx)\n",
    "\n",
    "i = 0\n",
    "dict_v = {}\n",
    "for word in uniq_word_set: # iterate over the uniq_word_set\n",
    "    dict_v[word] = i # assign a unique value to each key of dictionary\n",
    "    i+=1\n",
    "print(\"\\ndictionary of unique words \\n\",dict_v)\n",
    "\n",
    "dict_1 = {}\n",
    "for word in words_list: #iterate the words_list\n",
    "    if word not in dict_1: \n",
    "        dict_1[word] = words_list.count(word) # count the frequency of words and assign them as a value in a dictionary\n",
    "print(\"\\n dictionary of all words : \\n\",dict_1)\n",
    "\n",
    "print(\"\\n dictionary of files \\n\",files_dict)\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o2.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 Fill Term Document Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fill the term doc matrix by checking if the unique word exists in a file or not\n",
    "2. If it exists then substitute a 1 in term_doc_matrix (eg : TERM_DOC_MATRIX[file][word] = 1 ) \n",
    "3. Do the same for all the files present in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dictionary of unique words \n",
      " {'and': 0, 'umbrella': 1, 'book': 2, 'shoes': 3, 'this': 4, 'interesting': 5, 'my': 6, 'pen': 7, 'is': 8}\n",
      "[[0. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 1. 1. 1.]\n",
      " [0. 0. 1. 0. 0. 1. 1. 0. 1.]\n",
      " [0. 1. 0. 0. 1. 0. 1. 0. 1.]\n",
      " [1. 1. 0. 1. 1. 0. 1. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here    \n",
    "print(\"\\ndictionary of unique words \\n\",dict_v)\n",
    "dict_v\n",
    "term_mtrx\n",
    "path = r\"C:\\Users\\hp\\Downloads\\Assignmnet 2 - IRS\\files\"\n",
    "for filename,value in files_dict.items(): # take filename and its corresponding value and iterate the dictionary\n",
    "    file_path = os.path.join(path,filename)\n",
    "    if os.path.isfile(file_path) and fnmatch.fnmatch(filename, '*.txt'):\n",
    "        f = open(file_path) #open each file \n",
    "        words_list = f.read().lower().split() # make a list of word in each file\n",
    "        for word,count in dict_v.items(): #take word and its corresponding count and iterate the dictionary of unique vocab\n",
    "            if word in words_list: # if word of unique vocb exits in the list of file(words_list)\n",
    "                term_mtrx[value][count] = 1 # replace zero with 1 at that specific poistion\n",
    "print(term_mtrx)\n",
    "                \n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o4.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 Ask for a user Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For user query make a column vector of length of all the unique words present in a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colVector initially \n",
      " [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here    \n",
    "colVector = np.zeros((len_s,1)) # create column vector\n",
    "print(\"colVector initially \\n\",colVector)\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o5.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Write something for searching:  is my shoes\n",
      "Query is: is my shoes\n"
     ]
    }
   ],
   "source": [
    "query = input(\"\\nWrite something for searching:  \")\n",
    "print(\"Query is:\", query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Expected Output of query](images/Query.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7 Load Synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Synonyms Dictionary\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'write': [' compose', 'draft', 'author', 'create'],\n",
       " 'file': [' document', 'record', 'dossier', 'report'],\n",
       " 'example': [' illustration', 'instance', 'sample', 'demonstration'],\n",
       " 'query': [' question', ' inquiry', ' search', ' request'],\n",
       " 'synonym': [' equivalent', ' substitute', ' alternate', ' replacement'],\n",
       " 'retrieve': [' fetch', ' recover', ' obtain', ' bring back'],\n",
       " 'system': [' framework', ' structure', ' organization', ' arrangement'],\n",
       " 'search': [' seek', ' look for', ' explore', ' examine'],\n",
       " 'lost': [' misplaced', ' missing', ' forgotten', ' mislaid'],\n",
       " 'pen': [' write', ' ink', ' ballpoint', ' fountain'],\n",
       " 'paper': [' document', ' sheet', ' form', ' letter'],\n",
       " 'book': [' novel', ' volume', ' publication', ' tome'],\n",
       " 'read': [' peruse', ' scan', ' study', ' look at'],\n",
       " 'interesting': [' fascinating', ' engaging', ' intriguing', ' absorbing'],\n",
       " 'computer': [' machine', ' device', ' processor', ' laptop'],\n",
       " 'software': [' program', ' application', ' app', ' platform']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonym_file_path = r\"C:\\Users\\hp\\Downloads\\Assignmnet 2 - IRS\\synonyms.txt\"\n",
    "synonyms_dict = {} # dictionary to store synonyms\n",
    "#your code starts here\n",
    "file = open(synonym_file_path,\"r\")\n",
    "for line in file:\n",
    "    lst = line.strip().split(\":\")# remove \\n and make a list with 2 strings 1 before : and a string with multiple words after :(colon)\n",
    "    synonyms_dict[lst[0]] =lst[1].split(\",\") # list value as 0 index is given as key and string is converted into list by splitting it on basis of \",\" and list is corresponded value of key\n",
    "        \n",
    "        \n",
    "\n",
    "#your code ends here\n",
    "\n",
    "print(\"\\nSynonyms Dictionary\\n\")\n",
    "synonyms_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Synonym Dict Example](images\\Synonym_dict.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8 Extend User Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded Query\n",
      "['is', 'my', 'shoes']\n"
     ]
    }
   ],
   "source": [
    "expanded_query = []\n",
    "# Write code to expand the query using synonyms\n",
    "#your code starts here\n",
    "query_1 = query.split()\n",
    "for word in query_1: # check word in query_1 list \n",
    "    found = False # set flag\n",
    "    for key,value in synonyms_dict.items(): # take key value of synonyms_dict and iterate the dictionary\n",
    "        if word in [v.strip() for v in value]: #check word in list of value , \"v.strip() is used to remov space\"\n",
    "            expanded_query.append(word) # append word in the expanded_query\n",
    "            expanded_query.append(key)  # append key of synonyms_dict in the expanded_query\n",
    "            found = True\n",
    "            break\n",
    "    if not found:\n",
    "            expanded_query.append(word)\n",
    "           \n",
    "\n",
    "\n",
    "\n",
    "#your code ends here\n",
    "\n",
    "print(\"Expanded Query\")\n",
    "print(expanded_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Extended Query](images\\Expanded_Query.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now work with extended query and find the relevant documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 4, 'is': 6, 'my': 6, 'book': 2, 'pen': 1, 'interesting': 1, 'umbrella': 2, 'and': 1, 'shoes': 2}\n"
     ]
    }
   ],
   "source": [
    "# Check every word of query if it exists in the set of unique words or not\n",
    "query_l = query.split()\n",
    "for word in query_l:\n",
    "    if word in uniq_word_set: # If exists then increment the count of that word in word dictionary\n",
    "        dict_1[word] +=1 \n",
    "print(dict_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colVector after query : \n",
      " [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here    \n",
    "colVector = np.zeros((len_s,1)) # create column vector\n",
    "expanded_query\n",
    "col = colVector.T  # convert into 1d row vector\n",
    "for word,key in dict_v.items():\n",
    "    if word in expanded_query: #iterate over expanded_query list\n",
    "        col[0][key] = 1    #fill specific position\n",
    "colvector = col.T # convert into 1d column vector\n",
    "print(\"colVector after query : \\n\",colvector)\n",
    "\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o6.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7 Display Resultant Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display \n",
    "1. Resultant vector.\n",
    "2. Max value in resultant vector.\n",
    "3. Index of max value in resultant vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result\n",
      " [[2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]]\n",
      "\n",
      "max_index is \n",
      " 4\n",
      "\n",
      " max \n",
      " [3.]\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here  \n",
    "result = np.dot(term_mtrx,colvector)\n",
    "print(\"result\\n\",result)\n",
    "max_index = np.argmax(result) \n",
    "\n",
    "print(\"\\nmax_index is \\n\",max_index)#give index with maximum value\n",
    "print(\"\\n max \\n\",max(result))\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o7.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8 Display the contents of file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the code to identify the file_name having maximum value in the resultant vector and display its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The string you searched for exist in this f5.txt file and the contents of the files are : \n",
      " this is my umbrella and shoes\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here    \n",
    "max_index\n",
    "path = r\"C:\\Users\\hp\\Downloads\\Assignmnet 2 - IRS\\files\"\n",
    "swap_dict = {}\n",
    "for filename,value in files_dict.items():\n",
    "    swap_dict[value] = filename #swap key values to get easily access to index of file\n",
    "# print(swap_dict)\n",
    "if max(result)> 0:\n",
    "    filename = swap_dict[max_index] #get specific file according to value\n",
    "    file_path = os.path.join(path,filename)\n",
    "    if os.path.isfile(file_path) and fnmatch.fnmatch(filename, '*.txt'):\n",
    "        file = open(file_path,\"r\")\n",
    "        read_file = file.read()\n",
    "        print(f\"The string you searched for exist in this {swap_dict[max_index]} file and the contents of the files are : \\n {read_file}\")\n",
    "else:\n",
    "    print(\"no such word exist in any files\")\n",
    "\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations Now you are able to build your own small IRS which can work even if query does not have exact same words."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
